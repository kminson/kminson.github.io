[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "My About Page?",
    "section": "",
    "text": "So, uh when I was reading the instructions for setting up this page, I didn’t quite understand if I needed just either a Home or an About page, or if I needed both. Thus, I decided to do both just to make sure I don’t get points taken off for silly things. The only silly things I like is the ones that make me laugh and don’t bring down my GPA. Anyways, I already put a lot of basic information about myself on the Home page, so I don’t really know what to put on here. How about a fun fact? This year, 2025, is a perfect sum of the first ten cubes!\n\n\n0^3 + 1^3 + 2^3 + 3^3 + 4^3 + 5^3 + 6^3 + 7^3 + 8^3 + 9^3\n\n[1] 2025\n\n\nYes, I’m counting 0 as one of the first ten cubes. Sue me. I think the phrase “first ten cubes” is a lot cooler than “first nine cubes”. Maybe in 3025 I’ll use this fun fact again with the “first ten cubes” again, but this time with 10 instead of 0."
  },
  {
    "objectID": "tidytue1.html",
    "href": "tidytue1.html",
    "title": "Pokemon",
    "section": "",
    "text": "Every pokemon has a list of base stats that correspond to their abilities. A pokemon with a base speed stat of 10 will be faster than a pokemon with a base speed state of 5. Base stat totals are one way to roughly measure a pokemon’s total power level, by adding up the stat totals across all their stats. Generally, if a pokemon with a higher base stat total will be stronger than a pokemon with a lower one. A pokemon’s egg group also classifies what kind of pokemon it is. A dragon egg group pokemon will be pokemon that is dragon-like in some way, while a flying egg group pokemon might be a bird of some sort. I also created another measurement called size index, which takes a pokemon’s height and weight, and multiplies them together to create a unit of measurement that measures both the size and the density of a pokemon roughly. I then plotted every pokemon by their size index versus their base stat totals to see if there was a correlational relationship between the two. I also colored each pokemon by their primary egg group and created a regression line for each egg group so we can see a pattern for each individual egg group and compare them with one another.\n\n\nCode\npokemon_df |&gt;\n  mutate(bst = hp + attack + defense + special_attack + special_defense + speed) |&gt;\n  mutate(size_index = height * weight)|&gt;\n  \n  ggplot(aes(x = size_index, y = bst, color = egg_group_1)) +\n    geom_point(size = 2.0) +\n    scale_x_log10(labels = comma) +\n    geom_smooth(method = \"lm\", linewidth = 1.2, se = FALSE) +\n    labs(\n      x = \"Size Index (Height * Weight)\",\n      y = \"Base Stat Total\",\n      title = \"Size Index vs. Base Stat Total\",\n      color = \"Egg Group\"\n    ) +\n    theme(\n    text = element_text(size = 40),      \n    axis.title = element_text(size = 40),\n    axis.text = element_text(size = 30)\n  )\n\n\n\n\n\n\n\n\n\nCredit:\nTidyTuesday Page:\nhttps://github.com/rfordatascience/tidytuesday/tree/main/data/2025/2025-04-01\nDataset Original Source:\nhttps://github.com/williamorim/pokemon\nCurated by Frank Hull:\nhttps://github.com/frankiethull"
  },
  {
    "objectID": "tidytue2.html",
    "href": "tidytue2.html",
    "title": "Wealth Inequality After Taxes",
    "section": "",
    "text": "The visual below shows the change in Gini Index across selected countries after taxes and government benefits over multiple years. The change was calculated by subtracting the post-tax Gini Index from the pre-tax Gini Index. Since a higher value of Gini Index indicates a higher level of wealth inequality, a positive change means a lower level of wealth inequality post-taxes and benefits.\n\n\nCode\nincome_inequality_processed |&gt;\n  mutate(gini_change = gini_mi_eq - gini_dhi_eq) |&gt;\n  filter(Code %in% c(\"USA\", \"BEL\", \"LUX\", \"ISL\")) |&gt;\n  group_by(Entity) |&gt;\n  ggplot(aes(x = Year, y = gini_change)) +\n    geom_bar(stat = \"identity\") +\n    facet_grid(~ Entity, scales = \"free_y\") +\n    labs(\n      y = \"Change in Gini Index\",\n      x = \"Year\",\n      Title = \"Yearly Gini Index Change Across Selected Countries\"\n    ) +\n    theme(\n    text = element_text(size = 40),      \n    axis.title = element_text(size = 40),\n    axis.text = element_text(size = 20)\n  ) \n\n\n\n\n\n\n\n\n\nCredit:\nData Processed By:\nhttps://ourworldindata.org\nSources:\nhttps://www.lisdatacenter.org/our-data/lis-database/\nhttps://www.oecd.org/en/data/datasets/income-and-wealth-distribution-database.html\nhttps://public.yoda.uu.nl/geo/UU01/AEZZIT.html\nhttps://www.gapminder.org/data/documentation/gd003/\nhttps://population.un.org/wpp/downloads?folder=Standard%20Projections&group=Most%20used\nhttps://github.com/open-numbers/ddf--gapminder--systema_globalis\nTidyTuesday Link:\nhttps://github.com/rfordatascience/tidytuesday/blob/main/data/2025/2025-08-05/readme.md\nData Curated By:\nJoe Harmon and the Data Science Learning Community\nhttps://github.com/jonthegeek"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Minsong Kim’s Projects in R",
    "section": "",
    "text": "Hello! My name is Minsong Kim, first of my name, child of Chonghui Pak and Chaepil Kim, hailing from the land of the Republic of Korea. I am a sophomore at Pomona College, and I’m really not quite sure how much information I should put about myself in this bio. So, I’ll say that at my heart, I’m no scholar but just a simple lover boy &lt;/3. This is my website with my projects made with delight for my class, Foundations of Data Science, R.\n(Pictured above is my friend’s fish slippers)"
  },
  {
    "objectID": "proj2.html",
    "href": "proj2.html",
    "title": "Obama’s Tweets",
    "section": "",
    "text": "For this project, I’ve decided to take a look at former President Obama’s tweets while he was a president. Twitter is a social media platform. As you might have guessed from the name, its all about being social. Now, how social was Obama when he served as the US president? We’ll take a look at his mentioning habits.\n\n\nCode\ndetect_username &lt;- \"(?&lt;=@)\\\\w{1,15}\"\nobama_tweets &lt;- obama_tweets |&gt;\n  mutate(mentioned_user = str_extract_all(text, detect_username),\n         mentioned_user = \n           map(mentioned_user, ~if (length(.x) == 0){\n             NA_character_}\n             else .x),\n         has_mention = if_else(str_detect(text, detect_username),\n                               \"Yes\", \"No\"), \n         has_mention = factor(has_mention, levels = c\n                              (\"Yes\", \"No\")),\n         excl_count = str_count(text, \"!+\"),\n         ques_count = str_count(text, \"\\\\?+\"),\n         sentence_type = ifelse\n         (excl_count &gt; 0 & ques_count == 0, \"Exclamation\",\n           ifelse \n           (ques_count &gt; 0 & excl_count == 0, \"Question\",\n             ifelse \n             (excl_count &gt; 0 & ques_count &gt; 0, \"Both\", \"Neither\")\n             )\n           ),\n         sentence_type = factor(sentence_type, levels = c\n                                (\"Exclamation\",\n                                  \"Question\",\n                                  \"Both\",\n                                  \"Neither\"))\n         )\n\n\n\n\nCode\nuser_proportions &lt;- obama_tweets |&gt;\n  select(mentioned_user) |&gt;\n  unnest(mentioned_user) |&gt;\n  filter(!is.na(mentioned_user)) |&gt;\n  count(mentioned_user) |&gt;\n  mutate(proportion = n / sum(n)) |&gt;\n  filter(!n == 1) |&gt;\n  mutate(mentioned_user = fct_reorder(mentioned_user, proportion))\n\nmention_summary &lt;- obama_tweets |&gt;\n  count(has_mention) |&gt;\n  mutate(proportion = n / sum(n))\n\nstyle_data &lt;- obama_tweets |&gt;\n  count(sentence_type) |&gt;\n  mutate(proportion = n / sum(n))\n\n\n\n\nCode\nmention_summary |&gt;\n  ggplot(aes(x = has_mention, y = proportion, fill = has_mention)) +\n  geom_col() +\n  labs(\n    title = \"Proportion of Obama's tweets that include a mention\",\n    x = \"Did the tweet include a mention?\",\n    y = \"Proportion\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nFrom this table, we can see that President Obama didn’t really spend most of his time interacting with other users on Twitter. This includes all sorts of stuff like re tweeting other people’s tweets, or replying to tweets, since those things require the user to mention the original tweeter. It does make sense, since he was the President of the United States, so stuff like PR was probably very important to him, and he didn’t really have an incentive to engage other users. Still, try to be a bit less anti-social!\n\n\nCode\nuser_proportions |&gt;\n  ggplot(aes(\n    x = proportion, y = mentioned_user, fill = mentioned_user\n    )) +\n  geom_col() +\n  labs(\n    title = \"Obama's Most Mentioned Users\",\n    x = \"Proportion of Total Mentions\",\n    y = \"Username\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\",)\n\n\n\n\n\n\n\n\n\nLets take a look at who enjoyed President Obama’s mentions the most. I filtered out any username that Obama only mentioned once, since it cluttered up the visual and isn’t really important to see who Obama likes to interact with. But, man, isn’t this too little to be all the users Obama mentioned more than once? In fact, he tends to mention the user @POTUS much more than any other user, including his political ally @HillaryClinton, or @FLOTUS. It makes up nearly 10% of all his mentions! Makes Obama look a little bit like a clout chaser….\n\n\nCode\nstyle_data |&gt;\n  ggplot(aes(x = sentence_type, y = proportion, fill = sentence_type)) +\n  geom_col() +\n  labs(\n    title = \n      \"Proportion of Obama's Tweets as Exclamations/Questions\",\n    x = \"Style of tweet\",\n    y = \"Proportion\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(size = 12)\n    )\n\n\n\n\n\n\n\n\n\nNow lets take a look at what kind of style of tweets Obama likes to use. I classified tweets based on whether the tweet included an exclamation mark, a question mark, both, or neither. We can see that most of Obama’s tweets use neither of those punctuation marks, but he uses a lot more exclamation marks than question marks. He comes off a little bit like a mansplainer when we take a look at the data like this, especially since he rarely asks questions. Obama, its okay to admit when you don’t know something.\nCredit:\nData Sourced from:\nhttps://www.obamalibrary.gov/digital-research-room/archived-white-house-websites-and-social-media\nby the National Archives"
  },
  {
    "objectID": "proj3.html",
    "href": "proj3.html",
    "title": "Monty Hall Simulation",
    "section": "",
    "text": "On this page, we will be exploring the Monty Hall problem through simulations. The Monty Hall problem is a probability problem that follows as such. Say you are on a game show, where you are given three doors to choose from. One door has a car, which represents winning the game, while the other two have goats, which represents failing the game. You select one door at random. Then, the host reveals one of the doors you didn’t select, revealing a goat, and gives you the choice of either switching to the other door or staying with your initial choice. Should you choose to switch or not? The problem got its name from the TV show it was based off of, whose host’s name was Monty Hall. This problem has a very interesting history, where a female mathematician, by the name of Marilyn Savant, gave an answer and posted it on a newspaper. What followed was thousands of messages and mail telling her she was wrong, many with PhD’s, when she was in fact correct. Now lets see what the answer is!\nFirst we begin by coding a function called monty_hall that represents the game once. The function has one input that determines if the player chooses to switch or not.\n\n\nCode\nmonty_hall &lt;- function(switch_choice) {\n  doors &lt;- letters[1:3] #A character vector of a, b, c to represent the three doors; a is the prize door\n  first_choice &lt;- sample(doors, 1) #Randomly choose our first door\n  \n  \n  reveal &lt;- if (first_choice == \"a\") { #Randomly reveal either b or c if a is selected\n    sample(doors[doors != \"a\"], 1)\n  } else if (first_choice == \"b\") { #Otherwise, reveal the unselected non-prize door\n    \"c\"\n  } else {\n    \"b\"\n  }\n  \n  doors &lt;- doors[doors != reveal] #Reveal the selected door\n  \n  second_choice = if (switch_choice == 1) { \n    second_choice = sample(doors[doors != first_choice], 1) #If switch = 1, we switch to the other door\n  } else {\n    second_choice = first_choice #Otherwise, we stay with our first door\n  }\n\n  result = ifelse(second_choice == \"a\", #If our second choice is a, we win!\n                         \"Success!\",\n                         \"Dud...\"\n                  )\n  data.frame(second_choice, result) #Create a dataframe with a column showing final selected door and results\n}\n\n\nThen we map the function to a numeric vector that spans from 1 to 100,000, effectively running the function 100,000 times. This is our simulation.\n\n\nCode\nn &lt;- 100000 #Set the simulation count to 100,000\nswitch_result &lt;- 1:n |&gt; #Use mapping to simulate the function n times with switching\n  map(~ monty_hall(1)) |&gt;\n  list_rbind()\n\nswitch_summary &lt;- switch_result |&gt; #Condense the table of results to proportion of successes and failures\n  group_by(result) |&gt;\n  summarise(number = n()) |&gt;\n  mutate(proportion = number / sum(number))\n\nnoswitch_result &lt;- 1:n |&gt; #Repeat for no switching\n  map(~ monty_hall(0)) |&gt;\n  list_rbind()\n\nnoswitch_summary &lt;- noswitch_result |&gt;\n  group_by(result) |&gt;\n  summarise(number2 = n()) |&gt;\n  mutate(proportion2 = number2 / sum(number2))\n\n\nWe’ll take the results of this simulation and work it into a table for plotting, and finally create a visual with our results!\n\n\nCode\nfull_summary &lt;- full_join(switch_summary, noswitch_summary, by = \"result\") #Join the proportion results into one table\n\nplot_data &lt;- full_summary |&gt; #Create a new table for easier plotting\n  select(result, proportion, proportion2) |&gt;\n  pivot_longer(cols = starts_with(\"proportion\"),\n               names_to = \"strategy\",\n               values_to = \"proportion\") |&gt;\n  mutate(strategy = if_else(strategy == \"proportion\", \"Switch\", \"No Switch\")) |&gt;\n  mutate(result = fct_relevel(result, c(\"Success!\", \"Dud...\"))) |&gt;\n  mutate(strategy = fct_relevel(strategy, c(\"Switch\", \"No Switch\")))\n\nggplot(plot_data, aes(x = result, y = proportion, fill = strategy)) + #Plot!\n  geom_col(position = \"dodge\") +\n  labs(\n    title = \"Monty Hall Simulation Results of 100,000 Runs\",\n    x = \"Outcome\",\n    y = \"Proportion of Wins\",\n    fill = \"Strategy\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nAs you can see by the table, when the player chooses to switch, they have roughly 2/3rd odds to win, while only have 1/3rd odds to win if they choose not to switch. I was surprised because, even though I knew from previously reading about this problem that it was to the player’s advantage to switch, I had a misunderstanding as to why that was. I believed that by revealing a losing door, the remaining unselected door had 1/2 odds of being the winning door since there were only two doors left, but the initial door only had 1/3rd odds of winning since it was selected while there was still 3 doors. However, the correct logic is that by switching, the unselected door gives the player 2/3rd odds of winning, as it effectively gives the player the “odds” of both the unrevealed unselected door and the revealed unselected door. When Savant wrote her response to all those letters telling her she was wrong, she used this analogy.\n“Suppose there are a million doors, and you pick door #1. Then, the host, who knows what’s behind the door and will always avoid the one with a prize, opens them all except door #777,777. You’d switch to that door pretty fast, wouldn’t you?”\nI like this analogy a lot, because by scaling the problem to the extreme, Savant makes the solution a lot easier to grasp intuitively then it is with the problem’s original setup. There’s actually a whole Wikipedia page on this problem and all the research it spawned. The page has stuff like psychological tendacies why people intuitively grasp the wrong solution, how to mathematically prove the solution of the problem, different variants, etc. It’s all very fascinating stuff."
  }
]